# 라이브 스트리밍 데이터 처리 설계 설명

## 단계별 설명

### 1. client
- 사용자가 라이브 방송을 시작하거나 영상을 업로드한다.
- 전송되는 데이터는 **영상, 오디오, 메타데이터**가 하나로 묶인 원본 형태이다.

---

### 2. 전처리기 (비디오 분할)
- 원본 영상을 받아서 **비디오·오디오·메타데이터를 분리**한다.
- 영상이 너무 크면 일정 시간 단위(예: 10초 단위)로 **조각(GOP)** 으로 나눈다.
---

### 3. 메시지 큐
- 분리된 비디오를 병렬로 처리한다.
- 큐는 **비디오 추출, 오디오 추출, 메타데이터 추출** 작업자들에게 메시지를 전달한다.
---

### 4. 비디오 추출 → 인코딩 → 썸네일 생성
- **비디오 추출기**는 원본 데이터에서 영상 부분만 꺼낸다.
- 추출된 비디오는 **인코딩 서버**에서 여러 해상도(240p, 720p, 1080p 등)로 변환된다.
- 동시에 대표 이미지를 만들기 위해 **썸네일 생성기**가 작동한다.
---

### 5. 오디오 추출 → 인코딩
- 오디오 추출기는 영상에서 **소리만 분리**한다.
- 오디오 인코딩 서버는 파일을 압축하거나 형식을 변환한다(MP3, AAC 등).
---

### 6. 메타데이터 추출
- 영상의 길이, 파일 크기, 업로드한 사용자등 영상의 메타데이터 정보를 분리한다.
---

### 7 메세지 큐
- 인코딩된 비디오 및 데이터를 병렬로 처리한다.
- 큐는 **인코딩 비디오 저장소, API 서버** 작업자들에게 메시지를 전달한다.
---

### 8. 인코딩 비디오 저장소
- 인코딩이 완료된 비디오와 오디오는 이곳에 저장된다.
- 이 저장소는 **CDN의 원본** 역할을 한다.
- 즉, CDN이 여기에 있는 영상을 복사해서 전 세계 엣지 서버로 배포한다.
---

### 9. CDN
- CDN은 시청자에게 **가장 가까운 서버에서 영상 데이터를 전달**한다.
---

### 10. API 서버
- 인코딩이 완료된 영상의 상태, 썸네일, 제목 등을 관리한다.
---

### 11. Client (시청자)
- 시청자는 **CDN을 통해 인코딩된 영상 데이터를 재생**한다. 
- **API 서버**를 통해 영상 제목, 설명, 썸네일, 조회수, 댓글 등 메타데이터를 가져온다

